# VAbitnetUI Configuration
# Copy this file to .env and customize for your environment

# ============================================
# VOSK Configuration (Speech Recognition)
# ============================================

# Path to VOSK model directory
# Default: models/vosk-model-small-en-us-0.15
VOSK_MODEL_PATH=.\models\vosk-model-small-en-us-0.15

# ============================================
# BitNet Configuration (LLM Inference)
# ============================================

# BitNet API endpoint (local server)
BITNET_ENDPOINT=http://localhost:8081/completion

# Path to BitNet GGUF model file
BITNET_MODEL_PATH=.\bitnet_backend\models\bitnet_b1_58-large\ggml-model-i2_s.gguf

# Number of CPU threads for inference
# 0 = auto-detect (recommended)
# 1-N = specific thread count
BITNET_THREADS=0

# Context window size (tokens)
# Higher = more context, more memory usage
# Recommended: 2048-4096
BITNET_CTX_SIZE=2048

# Generation temperature (0.0-1.0)
# Lower = more focused/deterministic
# Higher = more creative/random
# Recommended: 0.7
BITNET_TEMPERATURE=0.7

# Server port for BitNet API
BITNET_SERVER_PORT=8081

# ============================================
# Application Settings
# ============================================

# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Enable verbose logging
VERBOSE=false

# Audio settings
AUDIO_SAMPLE_RATE=16000
AUDIO_CHANNELS=1

# ============================================
# VA Workstation Specific
# ============================================

# Set to true for VA deployment (disables any external connections)
VA_MODE=true

# Offline mode (no network checks)
OFFLINE_MODE=true
